# llm

* [Fine-tuning Zephyr 7B GPTQ with 4-Bit Quantization for Custom Data and Inference](https://github.com/bayjarvis/llm/tree/main/zephyr/finetune_gptq)

* [Harnessing Zephyr's Breeze: DPO Training on Mistral-7B-GPTQ for Language Model Alignment](https://github.com/bayjarvis/llm/tree/main/mistral/dpo)
