# llm

* [Fine-tuning Zephyr 7B GPTQ with 4-Bit Quantization for Custom Data and Inference](https://github.com/bayjarvis/llm/tree/main/zephyr/finetune_gptq)
